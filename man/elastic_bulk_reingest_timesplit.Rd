% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/elastic_functions.R
\name{elastic_bulk_reingest_timesplit}
\alias{elastic_bulk_reingest_timesplit}
\title{Re-ingest the contents of an Elasticsearch index, into potentially many indices based on the day of a time-stamp field.}
\usage{
elastic_bulk_reingest_timesplit(elasticsearch, timestamp_field, mapping = "")
}
\arguments{
\item{elasticsearch}{connection details for the Elasticsearch server we want to access (and optionally the index and type too).}

\item{timestamp_field}{a timestamp field that will be used to seperate documents into day-based indices.}

\item{mapping}{the new mapping to upload prior to re-ingesting the index (must be in raw JSON format as specified by Elasticsearch).}
}
\value{
TRUE or FALSE depending on the success of the operations.
}
\description{
When indices becomes large, index performance begins to deterioriate. This is especially so for logs file data that can contain many millions of documents.
When such an index becomes large it is more efficient to split it into many indices based on a time period (here chosen to be days).
\code{elastic_bulk_reingest_timesplit} takes an index that has become large and potentially unperformant, and splits it into multiple indices based on the day
of a specific timestamp field. The option to supply a non-default mapping is also provided.
}

